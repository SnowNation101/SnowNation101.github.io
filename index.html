<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Chenghao Zhang</title>

    <meta name="author" content="Chenghao Zhang">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Chenghao Zhang
                </p>
                <p style="text-align:center; font-style:italic; font-family: 'Comic Sans MS', 'Comic Sans', cursive; color: #888;">
                  "Against stupidity the very gods <br>
                  Themselves contend in vain."
                </p>
                <p>
                  I'm Chenghao David Zhang, a ðŸ“š Ph.D. student at the <a href="http://ai.ruc.edu.cn/">Gaoling School of Artificial Intelligence, Renmin University of China</a>, under the supervision of <a href="http://playbigdata.ruc.edu.cn/dou/">Prof. Zhicheng Dou</a>.
                  I earned my ðŸŽ“ B.Eng. degree in Software Engineering from the <a href="https://scs.bupt.edu.cn/index.htm">School of Computer Science, Beijing University of Posts and Telecommunications</a> in 2024.
                  My research focuses on ðŸŒˆ multimodal information retrieval and ðŸ‘€ vision-language models.
                  Outside my main research, I have a strong interest in ðŸ§© computer graphics.<br><br>
                  Always keen to explore cool, interesting, and meaningful research problems that push the boundaries of AI and create real-world impact.
                </p>
                <p style="text-align:center">
                  <a href="davidzhang101@outlook.com">Email</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=q4CnV3oAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://x.com/snownation_">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/snownation101">Github</a> &nbsp;/&nbsp;
                  <a href="https://space.bilibili.com/34135862">bilibili</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <img style="width:100%;max-width:100%;object-fit: cover; border-radius: 10%;" alt="profile photo" src="images/profile.jpg">
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm currently working on a unified multimodal retriever for RAG systems. Below are my prior works, with key papers <span class="highlight">highlighted</span>.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr bgcolor="#ffffd0">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/nyx.png" alt="Nyx" style="max-width:200px; max-height:150px; height:auto; width:auto; border-style:none;">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="">
                <span class="papertitle">Towards Mixed-Modal Retrieval for Universal Retrieval-Augmented Generation</span>
              </a>
              <br>
                <strong>Chenghao Zhang</strong>, Guanting Dong, Xinyu Yang, Zhicheng Dou
              <br>
              <em>arXiv</em>, Oct. 2025
              <br>
              <a href="https://arxiv.org/pdf/2510.17354">arXiv</a> |
              <a href="https://github.com/SnowNation101/Nyx">github</a> |
              <a href="https://huggingface.co/collections/SnowNation/nyx">hf collection</a> |
              <a href="https://huggingface.co/papers/2510.17354">hf paper</a>
              <p>We proposed Nyx, a unified mixed-modal retriever tailored for URAG scenarios, and constructed NyxQA, a large-scale mixed-modal QA dataset.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/ar-mcts.png" alt="AR-MCTS" style="max-width:200px; max-height:150px; height:auto; width:auto; border-style:none;">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="">
                <span class="papertitle">Progressive Multimodal Reasoning via Active Retrieval</span>
              </a>
              <br>
              Guanting Dong, <strong>Chenghao Zhang</strong>, Mengjie Deng, Yutao Zhu, Zhicheng Dou, Ji-Rong Wen
              <br>
              <em>ACL</em>, 2026
              <br>
              <a href="https://arxiv.org/pdf/2412.14835">arXiv</a>
              <p>A framework designed to progressively improve the reasoning capabilities of MLLMs through Active Retrieval (AR) and Monte Carlo Tree Search (MCTS). </p>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/flashrag.png" alt="FlashRAG" style="max-width:200px; max-height:150px; height:auto; width:auto; border-style:none;">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="">
                <span class="papertitle">FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation Research</span>
              </a>
              <br>
              Jiajie Jin, Yutao Zhu, Guanting Dong, Yuyao Zhang, Xinyu Yang, <strong>Chenghao Zhang</strong>, Tong Zhao, Zhao Yang, Zhicheng Dou, Ji-Rong Wen
              <br>
              <em>WWW</em>, Short-Paper, 2025
              <br>
              <a href="https://arxiv.org/abs/2405.13576">arXiv</a> |
              <a href="https://github.com/RUC-NLPIR/FlashRAG">github project</a>
              <p>A Python toolkit for the reproduction and development of RAG research. Including 36 pre-processed benchmark RAG datasets and 23 state-of-the-art RAG algorithms, and 7 reasoning-based methods that combine reasoning ability with retrieval.</p>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/dpa-rag.png" alt="DPA-RAG" style="max-width:200px; max-height:150px; height:auto; width:auto; border-style:none;">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="">
                <span class="papertitle">Understand what LLM needs: Dual preference alignment for retrieval-augmented generation</span>
              </a>
              <br>
              Guanting Dong, Yutao Zhu, <strong>Chenghao Zhang</strong>, Zechen Wang, Ji-Rong Wen, Zhicheng Dou
              <br>
              <em>WWW</em>, 2025
              <br>
              <a href="https://arxiv.org/pdf/2406.18676">arXiv</a>
              <p>A framework designed to align diverse knowledge preferences within RAG systems</p>
              </td>
            </tr>

            <tr>
              <td style="padding:16px;width:20%;vertical-align:middle">
                <img src="images/inters.png" alt="INTERS" style="max-width:200px; max-height:150px; height:auto; width:auto; border-style:none;">
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
              <a href="">
                <span class="papertitle">INTERS: Unlocking the Power of Large Language Models in Search with Instruction Tuning</span>
              </a>
              <br>
              Yutao Zhu,
              <a href="https://www.namespace-pt.com/">Peitian Zhang</a>,
              <strong>Chenghao Zhang</strong>,
              Yifei Chen,
              Binyu Xie,
              Zheng Liu,
              Jirong Wen,
              Zhicheng Dou
              <br>
              <em>ACL</em>, 2024
              <br>
              <a href="https://arxiv.org/pdf/2401.06532">arXiv</a> |
              <a href="data/inters.bib">bibtex</a> |
              <a href="https://github.com/DaoD/INTERS">code</a> |
              <a href="https://huggingface.co/datasets/yutaozhu94/INTERS">dataset</a>
              <p>A novel instruction tuning dataset, INTERS, encompassing 20 tasks across three fundamental IR categories: query understanding, document understanding, and query-document relationship understanding. The data are derived from 43 distinct datasets with manually written templates.</p>
              </td>
            </tr>

          </tbody></table>

          
					<table style="width:100%; margin:0 auto; border:0; border-spacing:0; padding:16px;"><tbody>
            <tr>
              <td>
                <h2>Services</h2>
                <!-- <h3>Reviewers</h3>
                <p>ACL, NIPS, ICLR</p> -->
                <h3>Teaching Assistant</h3>
                <ul style="text-align:justify;height: 150px;">
                  <li>Data Structures and Algorithms, 2024 Fall</li>
                  <li>Few Shot Learning, 2025 Fall</li>
                </ul>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
						
					  
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <p style="text-align:center; font-size:small; color:#666; font-style:italic;">
                  This website is adapted from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's template</a>. Many thanks!
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
